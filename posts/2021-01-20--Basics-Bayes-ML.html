<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2021-01-20">
<meta name="description" content="Bayesian methods can offer capabilities like uncertainty estimates and encoding domain knowledge directly into a model. This post provides an overview of Bayesian methods beginning with a review of probability before showing how it can be applied to the coin flipping problem. By the end, the reader will have a basic understanding of the methods and where to go from here.">

<title>J. Tyler Kirby - The Basics of Bayesian Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">J. Tyler Kirby</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../papers.html">
 <span class="menu-text">Papers and Talks</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/TylerKirby"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tyler-kirby/"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">The Basics of Bayesian Machine Learning</h1>
                  <div>
        <div class="description">
          Bayesian methods can offer capabilities like uncertainty estimates and encoding domain knowledge directly into a model. This post provides an overview of Bayesian methods beginning with a review of probability before showing how it can be applied to the coin flipping problem. By the end, the reader will have a basic understanding of the methods and where to go from here.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">machine_learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 20, 2021</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#reviewing-the-basics" id="toc-reviewing-the-basics" class="nav-link active" data-scroll-target="#reviewing-the-basics">Reviewing the Basics</a></li>
  <li><a href="#bayes-theorem" id="toc-bayes-theorem" class="nav-link" data-scroll-target="#bayes-theorem">Bayes’ Theorem</a></li>
  <li><a href="#coin-flipping-part-deux" id="toc-coin-flipping-part-deux" class="nav-link" data-scroll-target="#coin-flipping-part-deux">Coin Flipping Part Deux</a></li>
  <li><a href="#reasoning-with-the-posterior" id="toc-reasoning-with-the-posterior" class="nav-link" data-scroll-target="#reasoning-with-the-posterior">Reasoning With The Posterior</a></li>
  <li><a href="#known-unknowns" id="toc-known-unknowns" class="nav-link" data-scroll-target="#known-unknowns">Known Unknowns</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>If you’ve ever been dazzled, or perhaps terrified, by dense integral equations and perplexing terms such as <em>marginal log likelihood</em> and <em>posterior inference</em> when reading a new research paper, you are certainly not alone. For the uninitiated, Bayesian methods appear relegated to austere math-magicians at the heights of the ivory tower conjuring new results with arcane techniques. Fortunately, the fundamentals of Bayesian machine learning are much simpler than they appear and rightly so lest we forget their origins in 18th century Parisian gambling halls at the hands of one Pierre-Simon, marquis de Laplace. In this short post, I’ll outline Bayes’ theorem and how it lies at the heart of all methods in Bayesian machine learning. Internalizing and understanding this basic theorem is all that is required to become a practitioner of Bayesian methods. I will also touch upon some major problems of these methods such as prior elicitation and intractable posteriors. To conclude I will point to some open problems of interest in the field and point to more complete resources for mastering Bayesian machine learning.</p>
<section id="reviewing-the-basics" class="level1">
<h1>Reviewing the Basics</h1>
<p>Complete courses in statistics, probability, linear algebra, and calculus are required indeed to fully understand and appreciate the nuance and elegance of Bayesian methods, but the basic laws of probability theory are really all that’s needed to approach Bayes’ theorem. We’ll review them briefly below.</p>
<p>The <strong>Product Law</strong> allows us to compute the probability of two events occuring concurrently:</p>
<p><span class="math display">\[Pr(A \cap B) = Pr(B | A) \cdot Pr(A)\]</span></p>
<p>Note the term <span class="math inline">\(Pr(B | A)\)</span> in the equation above. This can be read as “the probability of <span class="math inline">\(B\)</span> given <span class="math inline">\(A\)</span>” and is called a <strong>conditional probability</strong>. As we shall soon see, Bayes’ Theorem is a formulation of conditional probability.</p>
<p>The <strong>Sum Law</strong> allows us to compute the probability of one event if we know the joint probabilities between it and another event:</p>
<p><span class="math display">\[Pr(A) = \sum_{i} Pr(A \cap B_i)\]</span></p>
<p>We assume that the events <span class="math inline">\(B\)</span> can be divided into partitions where we know the joint probability of <span class="math inline">\(A\)</span> and the partition <span class="math inline">\(B\)</span>. For example, suppose <span class="math inline">\(Pr(A)\)</span> is the probability of flipping heads on a two-sided coin and <span class="math inline">\(Pr(B)\)</span> is the probability of me using a fair coin. Let <span class="math inline">\(Pr(B_1)\)</span> be the probability that the coin is fair and <span class="math inline">\(Pr(B_2)\)</span> be the probability that the coin is unfair. Thus, we could compute the unknown <span class="math inline">\(Pr(A)\)</span> as <span class="math inline">\(Pr(A \cap B_1) + Pr(A \cap B_2)\)</span> assuming that we know the joint probabilities of events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, or, more simply, assuming we know the effect of an unfair coin on the probability of flipping heads. You may see how we can generalize the Sum Law to handle continuous cases by integrating over the partitions of <span class="math inline">\(B\)</span> rather than summing.</p>
</section>
<section id="bayes-theorem" class="level1">
<h1>Bayes’ Theorem</h1>
<p>With the two laws outlined above, we’re ready to tackle <strong>Bayes’ Theorem</strong>. Let’s begin with the simplest formulation of the theorem:</p>
<p><span class="math display">\[Pr(B|A) = \frac{Pr(A|B) Pr(B)}{Pr(A)}\]</span></p>
<p>The numerator is just the Product Law applied to the joint probability of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. Solving for <span class="math inline">\(P(B|A)\)</span> in the Product Rule yields Bayes’ Theorem above. We will need to go further, however, for this to be useful. In practice, finding <span class="math inline">\(Pr(A)\)</span> is really hard, so it is more common to substitute it with the result from the Sum Law:</p>
<p><span class="math display">\[Pr(B|A) = \frac{Pr(A|B) Pr(B)}{\sum_{i} Pr(A \cap B_i)}\]</span></p>
<p>We should generalize the expression for continuous variables since those will often be the variables provided. So far we have used discrete events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> to illustrate the results. Let’s introduce continuous variables <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> for our generalized expression:</p>
<p><span class="math display">\[p(b|a) = \frac{p(a|b) p(b)}{\int p(a|b) p(b) db}\]</span></p>
<p>The process of integrating <span class="math inline">\(p(a|b) p(b)\)</span> to find <span class="math inline">\(p(a)\)</span> is called <strong>marginalizing</strong> over the parameter <span class="math inline">\(b\)</span> and is extremely common in practice.</p>
<p>Each part of Bayes’ Theorem has a specific name and function. The probability <span class="math inline">\(p(b|a)\)</span>, which is the result we’re seeking to compute, is the <strong>posterior probability</strong> or belief. It is <em>posterior</em> from the Latin for <em>after</em> since it is the result we arrive at after calculating with Bayes’ Theorem. The term <span class="math inline">\(p(a|b)\)</span> is the <strong>likelihood</strong> since it represents the likelihood of <span class="math inline">\(a\)</span> given <span class="math inline">\(b\)</span>. The probability of <span class="math inline">\(b\)</span> is the <strong>prior probability</strong> or belief. We begin the Bayesian process with some idea of what we think the prior <span class="math inline">\(p(b)\)</span> is and after incorporating the new evidence presented in the likelihood <span class="math inline">\(p(a|b)\)</span> we arrive at a new belief of <span class="math inline">\(p(b)\)</span> weighted against the new evidence. Finally, we have the ugly term <span class="math inline">\(\int p(a|b) p(b) db\)</span> which is our <strong>marginal probability</strong> or belief. Note that in each definition I suggest probability and belief can be used interchangeably. In the Bayesian context, they most certainly can though this can get you into trouble mathematically elsewhere.</p>
</section>
<section id="coin-flipping-part-deux" class="level1">
<h1>Coin Flipping Part Deux</h1>
<p>I referenced coin flipping earlier for demonstrating the Sum Law. Now let’s treat this problem more fully using Bayes’ Theorem. Let <span class="math inline">\(p(\theta)\)</span> be the probability of observing heads. <span class="math inline">\(x\)</span> is the number of heads we observe after <span class="math inline">\(n\)</span> flips. We want to formulate a posterior probability for <span class="math inline">\(\theta\)</span> given some likelihood and prior. Likelihood probabilities typically are strongly related to the structure of the problem. Our problem is determining the probability of a discrete event occurring given so many trials. A quick gloss of the appendix of any statistics textbook would lead us to choosing a <strong>binomial distribution</strong> for modeling this likelihood:</p>
<p><span class="math display">\[Pr(x | n, \theta) = {n \choose x} \theta^x (1 - \theta)^{n-x}\]</span></p>
<p>Now on to the prior. There are really two guiding principles for selecting a prior distribution: 1) domain knowledge and 2) mathematical convenience. If we have some deep knowledge about the problem, then we could encode that information into our posterior belief by way of the prior belief. For example, if I truly believed the coin was fair, I may just set <span class="math inline">\(p(\theta) = 0.5\)</span> and call it a day. Of course this would mean that if the coin was unfair I may not be able realize this in my posterior belief. Therefore, selecting a distribution is more appropriate. Which distribution should I select? Again, maybe prior knowledge of the problem will help you here. Perhaps we think the fairness of the coin is Gaussian distributed, or, for some odd reason we may believe it’s Gamma distributed. In practice though we want a prior distribution that will not make our life difficult. We Bayesians are lazy. Remember that we will soon have to solve <span class="math inline">\(\int p(a|b) p(b) db\)</span>, so let’s choose a distribution that will make this easy for us. Prior distributions that play well with their likelihood companion are <strong>conjugate priors</strong>. <a href="https://en.wikipedia.org/wiki/Conjugate_prior">Here</a> is a great Wikipedia page on conjugacy that includes a table of common conjugate priors. The prior distribution conjugate to the Binomial distribution is the Beta distribution:</p>
<p><span class="math display">\[p(\theta | \alpha, \beta) = \frac{1}{\int^1_0 \theta^{\alpha - 1} (1- \theta)^{\beta-1}d\theta} \theta^{\alpha -1} (1-\theta)^{\beta-1}\]</span></p>
<p>The equation above may look messy, but we should just understand it as the continuous analog of the Binomial distribution.</p>
<p>With our likelihood and prior beliefs in hand, we can now formulate our posterior belief of <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[p(\theta| x, n, \alpha, \beta) = \frac{Pr(x | n, \theta) p(\theta | \alpha, \beta)}{\int Pr(x | n, \theta) p(\theta | \alpha, \beta) d\theta}\]</span></p>
<p>The algebra for reducing the above is unfortunately pretty hairy but because of our careful selection of a conjugate prior, we know that the result will itself be a Beta distribution. It has the following form:</p>
<p><span class="math display">\[p(\theta| x, n, \alpha, \beta) = Beta(\alpha + x, \beta + n - x)\]</span></p>
<p>We’re finished! We’ve modeled the probability of flipping heads as a Beta distribution incorporating the result of trials, the number of trials, and our prior beliefs. You may wonder at this point what we should set <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> to in this model. Again, this relies on prior beliefs. We can set both to 1 which will have the result of saying each possible value of <span class="math inline">\(\theta\)</span> is equally likely. We may set <span class="math inline">\(\alpha = 500\)</span> and <span class="math inline">\(\beta = 1000\)</span> which would indicate that we’re pretty confident that the coin is fair. We can even make the problem more complex and place priors on our priors, which are called <strong>hyperpriors</strong>. This process of selecting priors is called <strong>prior elicitation</strong> and is a key problem in Bayesian machine learning. If we select good priors, the model will converge much faster than traditionally methods. If we are egregiously wrong it will take much longer to reach convergence. We must balance picking mathematically convenient priors with priors that reflect the problem fairly. In the case of coin flipping, this is relatively easy. In machine learning this proves to be far more difficult.</p>
</section>
<section id="reasoning-with-the-posterior" class="level1">
<h1>Reasoning With The Posterior</h1>
<p>This may all seem like a lot of work. Why can’t we just work with the likelihood directly and call it a day? That is essentially what we do in most other machine learning methods that rely on <strong>maximum likelihood estimation</strong> (MLE) for parameter fitting, but it does have one big limitation. The results of MLE methods are not probabilities, they are point estimates. This unfortunately means we cannot quantify our uncertainty of the prediction rigorously which can be very problematic. At the end of the day, machine learning is about automated decision making. We humans weigh our decisions by the certainty we have in the evidence. If you believe that it will rain tomorrow because the weather man was right yesterday, your belief that it will rain the day after that will inevitably be weighted by whether the weather will be right tomorrow. Our models should follow the same principles to make the right decisions. Luckily, Bayesian methods make this very easy for us. A posterior belief is much more powerful than a point estimate since it is represented as a probability distribution. Consider the posterior belief from the previous section <span class="math inline">\(p(\theta| x, n, \alpha, \beta)\)</span>. If we wanted to compute a <strong>95% credible interval</strong> for this belief, meaning construct some interval where it is 95% likely for the parameter <span class="math inline">\(\theta\)</span> to lie, we simply find bounds where the following is true</p>
<p><span class="math display">\[0.95 = Pr(\theta \in (a, b)| x, n, \alpha, \beta) = \int^a_b p(\theta| x, n, \alpha, \beta) d\theta\]</span></p>
<p>Similarly, we can <strong>hypothesis test</strong> our posterior belief by working with the same integral representation. We can formulate the hypothesis that <span class="math inline">\(\theta=0.5\)</span>, i.e.&nbsp;the coin is fair, as</p>
<p><span class="math display">\[p(\theta = 0.5| x, n, \alpha, \beta) = \int^{0.5}_{0.5} p(\theta = 0.5| x, n, \alpha, \beta) d\theta\]</span></p>
<p>The result of the hypothesis test above is more useful than its Frequentist counterpart since we receive a probability of the hypothesis being true rather than a mere indication to accept or reject.</p>
<p>Clearly the posterior belief has a central role in Bayesian machine learning, and when it takes form of a known distribution like the Beta distribution, integrating it and using it for predictions is trivial. Our world though is more complex than what the pages of a mathematical appendix can describe. We are often left working with <strong>intractable posteriors</strong> when our likelihood and prior are not conjugate. For example, in Bayesian logistic regression the Bernoulli likelihood and Gaussian prior lead us to a posterior we cannot express analytically. We are not totally at a loss however. Instead, we can use methods of approximation. Often times we’re not interested in all the details of a posterior belief. Again considering Bayesian logistic regression, we really just need the expectation of the posterior to perform inference. A common trick in this case is to use the <strong>Laplace Approximation</strong> which superimposes a Gaussian over the intractable distribution and sets its mean to the mode of the intractable. Other methods include <strong>Expectation Propagation</strong> and <strong>Variational Inference</strong> that are more common in complex models like <strong>Gaussian processes</strong> and <strong>Deep Bayes Nets</strong>. We can also use traditional computation methods like <strong>Markov Chain Monte Carlo</strong> for approximating posteriors though in practice those are too intense to include in a training loop for machine learning.</p>
</section>
<section id="known-unknowns" class="level1">
<h1>Known Unknowns</h1>
<p>Bayesian machine learning is a large and growing field. Some areas of active research naturally follow some problems we discussed above such as how to pick good priors and how to deal with tricky posteriors. Others areas aim to Bayes-ify results from other fields. Simply google “Bayesian method-of-choice” and be inundated with the likes of Bayesian LSTMs, Bayesian PCA, Bayesian decision trees etc. It has been extremely useful for statisticians and scientists to be able to quantify how much they do not know, and as machine learning continues to share the brunt of decision-making, working with uncertainty will only become more important.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>